{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.lemagit.fr/visuals/LeMagIT/hero_article/Societe-General-logo.jpg)\n",
    "\n",
    "# Fight against financial crimes \n",
    "\n",
    "## Context\n",
    "\n",
    "Banks are investing a lot of money to prevent financial frauds. One of them is Credit Card Fraud. To give a little context, credit cards frauds:\n",
    "\n",
    "* Global losses to credit card fraud approximates $35 billion annually\n",
    "* The amount of credit card data available on the dark web increased by 135% last year.\n",
    "* 130,928 credit card fraud reports were recorded in the United States in 2018.\n",
    "\n",
    "No need to say that this is a huge issue. [Societe GÃ©nÃ©rale](https://www.societegenerale.com/en/ai-no-longer-just-option-finance), one of the biggest european banks, led innovation initiatives to use AI to detect credit card fraud more efficiently. \n",
    "\n",
    "They provided you with an anonymized dataset and they need you to build a ML algorithm that:\n",
    "\n",
    "* Is able to accurately predict credit card fraud\n",
    "* Is not black box - They need to be able to trace how the algorithm got the result it came up with \n",
    "\n",
    "## Dataset\n",
    "\n",
    "Dataset can be found here ðŸ‘‰ [CreditCardFraud.csv](https://lead-program-assets.s3.eu-west-3.amazonaws.com/M01-Distributed_machine_learning/datasets/creditcard.csv)\n",
    "\n",
    "## Exercise - Part I - Train a model locally using Ray\n",
    "\n",
    "Let's train a classification model that will predict fraud on the transactions in the dataset.\n",
    "\n",
    "1. Start by importing the needed dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import  StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import joblib\n",
    "from ray.util.joblib import register_ray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load the dataset, isolate the predictors from the target variable, and split the dataset between a training set and a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://lead-program-assets.s3.eu-west-3.amazonaws.com/M01-Distributed_machine_learning/datasets/creditcard.csv')\n",
    "\n",
    "X = data.drop(\"Class\", axis=1)\n",
    "y = data[\"Class\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Build a [pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) with two steps: a standardization, then a random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline(steps=[\n",
    "        (\"standard_scaler\", StandardScaler()),\n",
    "        (\"classifier\", RandomForestClassifier())\n",
    "    ], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Train the model with `joblib` using `ray` as the parallelization backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 11:36:27,779\tINFO ray_backend.py:74 -- Starting local ray cluster\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ... (step 1 of 2) Processing standard_scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 11:36:29,530\tINFO worker.py:1908 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8266 \u001b[39m\u001b[22m\n",
      "2025-06-20 11:36:30,085\tWARNING pool.py:589 -- The 'context' argument is not supported using ray. Please refer to the documentation for how to control ray initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  28.4s\n"
     ]
    }
   ],
   "source": [
    "register_ray()\n",
    "\n",
    "with joblib.parallel_backend('ray'):    \n",
    "    model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In production environment you would most likely have to submit your parallel jobs to a remote cluster. A remote cluster in the cloud is not cheap, so for testing purposes, let's start a ray cluster on kubernetes using our local machine on minikube."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Part II - Train a model on a Ray Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case the local ray cluster is still in use, let's stop it.\n",
    "```shell\n",
    "ray stop \n",
    "```\n",
    "\n",
    "As a reminder, here are the commands you may use to start your cluster on minikube (feel free to change the resources setup according to your machine): \n",
    "\n",
    "```shell\n",
    "minikube start --cpus=5 --memory=7995\n",
    "```\n",
    "\n",
    "```shell\n",
    "minikube dashboard\n",
    "```\n",
    "\n",
    "```shell\n",
    "helm repo add kuberay https://ray-project.github.io/kuberay-helm/\n",
    "```\n",
    "\n",
    "```shell\n",
    "helm install kuberay-operator kuberay/kuberay-operator --version 1.0.0\n",
    "```\n",
    "\n",
    "You may create a file called `ray-cluster.yaml` like :\n",
    "```yaml\n",
    "head:\n",
    "  enableInTreeAutoscaling: true\n",
    "  resources:\n",
    "    limits:\n",
    "      cpu: \"2\"\n",
    "      # To avoid out-of-memory issues, never allocate less than 2G memory for the Ray head.\n",
    "      memory: \"3G\"\n",
    "    requests:\n",
    "      cpu: \"2\"\n",
    "      memory: \"3G\"\n",
    "\n",
    "\n",
    "worker:\n",
    "  replicas: 1\n",
    "  resources:\n",
    "    limits:\n",
    "      cpu: \"2\"\n",
    "      memory: \"3G\"\n",
    "    requests:\n",
    "      cpu: \"2\"\n",
    "      memory: \"3G\"\n",
    "```\n",
    "\n",
    "```shell\n",
    "helm install raycluster kuberay/ray-cluster --version 1.3.0 --set 'image.tag=2.41.0-aarch64' -f ray-cluster.yaml\n",
    "```\n",
    "\n",
    "```shell\n",
    "kubectl port-forward --address 0.0.0.0 service/raycluster-kuberay-head-svc 8265:8265\n",
    "```\n",
    "\n",
    "```shell\n",
    "ray job submit --working-dir=. --runtime-env=runtime-env.json --address=\"http://127.0.0.1:8265\" -- python ray_train.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Now that our cluster is up and running, write a script to submit a hyperparameter tuning job to our cluster, and submit using the ray CLI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See ray_train.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ray",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
