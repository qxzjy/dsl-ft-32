{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on Ray cluster\n",
    "\n",
    "Now that we've discovered ray train, let's try to use on a ray cluster. \n",
    "Let's start with a reminder on how to build a ray cluster on kubernetes using minikube.\n",
    "\n",
    "### Install Ray cluster\n",
    "\n",
    "Now that we've experimented a little with ray locally, let's deploy it on a k8 cluster.\n",
    "\n",
    "#### Prerequisites\n",
    "\n",
    "Make sure you have installed:\n",
    "\n",
    "- `minikube`\n",
    "- `helm`\n",
    "\n",
    "#### Deploy Ray on Kubernetes\n",
    "\n",
    "The first step is to setup a k8 cluster\n",
    "\n",
    "```shell\n",
    "minikube start\n",
    "```\n",
    "\n",
    "We are going to use the minikube dashboard in order to monitor our cluster's activity:\n",
    "\n",
    "```shell\n",
    "minikube dashboard\n",
    "```\n",
    "\n",
    "Then using helm, let's import the repository implementing ray on a kubernetes cluster:\n",
    "\n",
    "```shell\n",
    "helm repo add kuberay https://ray-project.github.io/kuberay-helm/\n",
    "```\n",
    "\n",
    "The first step is to install the kuberay-operator, which will serve as our ray cluster management tool on kubernetes.\n",
    "\n",
    "```shell\n",
    "helm install kuberay-operator kuberay/kuberay-operator --version 1.0.0\n",
    "```\n",
    "\n",
    "Once the KubeRay operator is running, we are ready to deploy a RayCluster. To do so, we create a RayCluster Custom Resource (CR) in the default namespace.\n",
    "\n",
    "```shell\n",
    "helm install raycluster kuberay/ray-cluster --version 1.0.0\n",
    "```\n",
    "\n",
    "It is possible to monitor our ray cluster as well as connect to it through the following service. Let's find our what port it is available on.\n",
    "\n",
    "```shell\n",
    "kubectl get service raycluster-kuberay-head-svc\n",
    "```\n",
    "\n",
    "Now that we have the name and address of the service, we can use port-forwarding to access the Ray Dashboard port (8265 by default).\n",
    "\n",
    "```shell\n",
    "kubectl port-forward --address 0.0.0.0 service/raycluster-kuberay-head-svc 8265:8265\n",
    "```\n",
    "\n",
    "You may get a `port already in use` error, in that case, your cluster may already be available on [localhost:8265](http://localhost:8265)\n",
    "\n",
    "Let's submit our first job to our brand new cluster.  The following job's logs will show the Ray cluster's total resource capacity, including 2 CPUs.\n",
    "```shell\n",
    "ray job submit --address http://localhost:8265 -- python -c \"import ray; ray.init(); print(ray.cluster_resources())\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Ray Components\n",
    "\n",
    "Now Ray is a vast library. At the heart of Ray is the concept of distributing tasks accross a cluster of computers. Here is everything you can do:\n",
    "\n",
    "![crack](https://lead-program-assets.s3.eu-west-3.amazonaws.com/M01-Distributed_machine_learning/Ray_components.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take advantage of the cluster to launch a ray train job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "\n",
    "import ray.train.torch\n",
    "\n",
    "def train_func():\n",
    "    # Model, Loss, Optimizer\n",
    "    model = resnet18(num_classes=10)\n",
    "    model.conv1 = torch.nn.Conv2d(\n",
    "        1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
    "    )\n",
    "    # [1] Prepare model.\n",
    "    model = ray.train.torch.prepare_model(model)\n",
    "    # model.to(\"cuda\")  # This is done by `prepare_model`\n",
    "    criterion = CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Data\n",
    "    transform = Compose([ToTensor(), Normalize((0.5,), (0.5,))])\n",
    "    data_dir = os.path.join(tempfile.gettempdir(), \"data\")\n",
    "    train_data = FashionMNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "    train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "    # [2] Prepare dataloader.\n",
    "    train_loader = ray.train.torch.prepare_data_loader(train_loader)\n",
    "\n",
    "    # Training\n",
    "    for epoch in range(10):\n",
    "        if ray.train.get_context().get_world_size() > 1:\n",
    "            train_loader.sampler.set_epoch(epoch)\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            # This is done by `prepare_data_loader`!\n",
    "            # images, labels = images.to(\"cuda\"), labels.to(\"cuda\")\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # [3] Report metrics and checkpoint.\n",
    "        #metrics = {\"loss\": loss.item(), \"epoch\": epoch}\n",
    "        #with tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
    "        #    torch.save(\n",
    "        #        model.module.state_dict(),\n",
    "        #        os.path.join(temp_checkpoint_dir, \"model.pt\")\n",
    "        #    )\n",
    "        #    ray.train.report(\n",
    "        #        metrics,\n",
    "        #        checkpoint=ray.train.Checkpoint.from_directory(temp_checkpoint_dir),\n",
    "        #    )\n",
    "        #if ray.train.get_context().get_world_rank() == 0:\n",
    "        #    print(metrics)\n",
    "# [4] Configure scaling and resource requirements.\n",
    "scaling_config = ray.train.ScalingConfig(num_workers=3, use_gpu=False)\n",
    "\n",
    "# [5] Launch distributed training job.\n",
    "trainer = ray.train.torch.TorchTrainer(\n",
    "    train_func,\n",
    "    scaling_config=scaling_config,\n",
    "    # [5a] If running in a multi-node cluster, this is where you\n",
    "    # should configure the run's persistent storage that is accessible\n",
    "    # across all worker nodes.\n",
    "    # run_config=ray.train.RunConfig(storage_path=\"s3://...\"),\n",
    ")\n",
    "result = trainer.fit()            \n",
    "\n",
    "```\n",
    "\n",
    "Copy the above script in a file you will call \"ray_train_demo.py\" and then run in your terminal:\n",
    "\n",
    "```shell\n",
    "ray job submit --runtime-env-json='{\"working_dir\": \"./\", \"pip\": [\"ray[train]\", \"torch\", \"torchvision\", \"numpy\"]}' --address=\"http://127.0.0.1:8265\" -- python ray_train_demo.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources ðŸ“šðŸ“š\n",
    "\n",
    "[Ray Train](https://docs.ray.io/en/latest/train/distributed-tensorflow-keras.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ray",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
